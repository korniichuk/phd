{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readability. Extra columns\n",
    "## Add extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from promovolt.readability import sentencesCounter, wordsCounter \n",
    "from promovolt.syllables import wordSyllablesCounterEn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('readability_20201124.pkl')  # 465 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add `asl_flesch` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asl_flesch(text):\n",
    "    \n",
    "    asl = None\n",
    "    \n",
    "    words_num, words = wordsCounter(text, 'en')  \n",
    "    sentences_num = sentencesCounter(text, 'en')[0]\n",
    "    \n",
    "    for c in text:\n",
    "        if c in (':', ';'):\n",
    "             sentences_num += 1\n",
    "                               \n",
    "    if sentences_num != 0:\n",
    "        asl = words_num / sentences_num\n",
    "    return asl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['asl_flesch'] = df.text.apply(asl_flesch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add `asw_flesch` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asw_flesch(text):\n",
    "    \n",
    "    asw = None\n",
    "    \n",
    "    words_num, words = wordsCounter(text, 'en')\n",
    "                \n",
    "    syllables_num = 0\n",
    "    for word in words:\n",
    "        if len(word) <= 3:\n",
    "            syllables_num += 1\n",
    "        elif ((word[len(word)-2] + word[len(word)-1] == 'ed') or (word[len(word)-2] + word[len(word)-1] == 'es')):\n",
    "            syllables_num += wordSyllablesCounterEn(word) - 1\n",
    "        else:    \n",
    "            syllables_num += wordSyllablesCounterEn(word)\n",
    "\n",
    "    if words_num != 0:\n",
    "        asw = syllables_num / words_num\n",
    "    return asw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['asw_flesch'] = df.text.apply(asw_flesch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add `asl_fog` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asl_fog(text):\n",
    "    \n",
    "    asl = None\n",
    "           \n",
    "    totalWords, words = wordsCounter(text, 'en')\n",
    "    totalSentences, sentences = sentencesCounter(text, 'en')                          \n",
    "         \n",
    "    if totalSentences != 0:\n",
    "        asl = totalWords / totalSentences\n",
    "    return asl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['asl_fog'] = df.text.apply(asl_fog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add `ppw_fog` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppw_fog(text):\n",
    "    \n",
    "    ppw = None\n",
    "    \n",
    "    pathCompoundWordsDictEn = os.path.abspath('promovolt/resources/compound_words_en.txt')\n",
    "    with open(pathCompoundWordsDictEn, 'r', encoding='utf-8') as f:\n",
    "        compoundWordsEnDict = f.read().splitlines()\n",
    "        \n",
    "    totalWords, words = wordsCounter(text, 'en')\n",
    "    totalSentences, sentences = sentencesCounter(text, 'en')\n",
    "    \n",
    "    totalHardWords = 0\n",
    "    for word in words:\n",
    "        if ((wordSyllablesCounterEn(word) == 3) and\n",
    "            ((word[len(word)-2] + word[len(word)-1] == 'ed') or (word[len(word)-2] + word[len(word)-1] == 'es'))):\n",
    "            continue          \n",
    "        if wordSyllablesCounterEn(word) >= 3:\n",
    "            if '-' not in word:\n",
    "                lowerWord = word.lower()\n",
    "                if lowerWord not in compoundWordsEnDict:\n",
    "                    if not(word[0].isupper()):                          \n",
    "                        totalHardWords += 1                \n",
    "                    else:                  \n",
    "                        wordPattern = re.compile(\"\\\\b\" + word + \"\\\\b\")                        \n",
    "                        startSwitch = None\n",
    "                        insideSwitch = None\n",
    "                        for sentence in sentences:                                               \n",
    "                            if wordPattern.findall(sentence) != []:\n",
    "                                if sentence.startswith(word): \n",
    "                                    startSwitch = True\n",
    "                                else:\n",
    "                                    insideSwitch = True\n",
    "                                sentence = sentence[len(word):]\n",
    "                                if wordPattern.findall(sentence) != []:\n",
    "                                    insideSwitch = True\n",
    "                        if (startSwitch == True) and (insideSwitch == None):\n",
    "                            totalHardWords += 1\n",
    "                            \n",
    "         \n",
    "    if totalWords != 0:    \n",
    "        ppw =  100 * (totalHardWords / totalWords)\n",
    "    return ppw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ppw_fog'] = df.text.apply(ppw_fog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('readability_extra_20201124.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson correlation coefficient (PCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('readability_extra_20201124.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(method='pearson').cvr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
